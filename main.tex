\documentclass[10pt]{article}
\usepackage[a4paper,bottom=0.8in, left=0.8in, right=0.8in, top=0.8in]{geometry}
\usepackage{graphicx}
\usepackage{environ}
\usepackage[usenames]{xcolor}
\usepackage{url}
\usepackage[colorlinks=true,linkcolor=cyan,citecolor=blue]{hyperref}
%\usepackage{subfigure}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage[utf8]{inputenc}
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=cyan
    }
\usepackage{microtype}
\linespread{1.25} % to get 1.5 linespacing
\usepackage{float}
\usepackage{tabularx,booktabs}
\usepackage{orcidlink}
\usepackage[misc]{ifsym}
\usepackage{enumitem}
%\usepackage[caption = false]{subfig}

\usepackage{listings}
\lstset{basicstyle=\small\ttfamily,
  showstringspaces=false,
  commentstyle=\color{teal},
  keywordstyle=\color{teal}}

\newsavebox{\figsavebox}

\newif\ifhidefigures

\NewEnviron{conditionalfigure}[1][ht]{%
  \ifhidefigures
    % hide this figure
    \let\oldlabel\label
    \renewcommand{\label}[1]{\gdef\labelname{##1}}% store label name
    \renewcommand{\caption}[1]{##1}% make \caption just print its argument
    \begin{lrbox}{\figsavebox}
      \BODY % capture enture figure body
    \end{lrbox}
    % step counter with reference and mark with label
    \refstepcounter{figure}\oldlabel{\labelname}
  \else
    % traditional figure environment
    \begin{figure}[#1]
      \BODY
    \end{figure}
  \fi
}

\newcommand{\beginsupplement}{%
        \setcounter{table}{0}
        \renewcommand{\thetable}{S\arabic{table}}%
        \setcounter{figure}{0}
        \renewcommand{\thefigure}{S\arabic{figure}}%
        \setcounter{section}{0}
        \renewcommand{\thesection}{S\arabic{section}}%
      }

%\usepackage[sort&compress,numbers,square]{natbib}
%\bibliographystyle{mplainnat}

\title{\texttt{denet}, a lightweight command-line tool for process monitoring in benchmarking and beyond}

\author{Ben Carrillo \orcidlink{0009-0003-5704-4151}, Izaskun Mallona \orcidlink{0000-0002-2853-7526}\\
\\
University of Zurich and SIB Swiss Institute of Bioinformatics, Zurich, Switzerland \\ 
{\small \Letter: \{\texttt{benjamincarrillochica,izaskun.mallona\}@mls.uzh.ch}}
}

\date{}

\begin{document}
\maketitle
	
\section*{Abstract} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\paragraph{Summary:} \texttt{denet} is a lightweight process monitoring utility providing real-time resource profiling of running processes. Denet reports CPU, memory, disk I/O, network activity, and thread usage, including recursive child monitoring, with adaptive sampling rates. Denet offers both a command-line interface (CLI) with colorized outputs and a Python API for inclusion in other software. Its output formats are structured in either JSON, JSONL, or CSV, and include performance metrics as well as process metadata, including PID and the executed command. The ease to parse profiling results make denet suitable for benchmarking, debugging, monitoring, and optimizing data-intensive pipelines in bioinformatics and other fields. 

\paragraph{Availability and implementation:} \texttt{denet} is open-source software released under the GPLv3 license and maintained at \url{https://github.com/btraven00/denet}. It is implemented in Rust, with Python bindings provided via maturin, and can be installed from Cargo (\texttt{cargo install denet}) or PyPI (\texttt{pip install denet}). Most functionality does not require administrative privileges, enabling use on cloud platforms, HPC clusters, and standard Linux workstations. Certain advanced features, such as planned eBPF support, may require elevated permissions. Documentation, including usage examples and API references, is provided.

\vspace{1cm}

\noindent\textbf{Keywords:} resource profiling, workflow, benchmarking, bioinformatics

\clearpage


\section*{Introduction}  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\label{sec:intro}

Granular resource profiling data (CPU and memory usage, disk and network I/O)  drives bioinformatics performance optimization at multiple levels: guiding code improvements during tool development, informing the tuning of execution parameters, and shaping the design of the overall workflow.

Standard command-line tools are poorly suited for this task in automated settings: i, \emph{system-level profilers} (top, htop) lack process-specificity, making it difficult to isolate the resource footprint of a single job; ii, \emph{process-summary utilities} (time) report only cumulative totals upon completion, missing the real-time dynamics that often indicate bottlenecks. Furthermore, the unstructured, text-based output of these tools is designed for interactive use, not automated parsing. This characteristic hinders their integration into workflow management systems and complicates systematic, reproducible performance profiling.

Major workflow systems, such as make, snakemake or nextflow, provide either none or non-fine-grained nor customizable resource profiling. In this context, we describe a new monitoring toolkit, \texttt{denet} (Turkish: `inspection' or `check'), that could be either used interactively by coupling its CLI to specific commands, or embedded into scripts and/or workflow managers.

\section*{Implementation and capabilities}

\subsection*{Adaptive profiling with user-provided resolution}

\texttt{denet} provides sampling at regular time units (e.g., milliseconds). As an alternative and a main innovation, the tool also offers an \emph{adaptive sampling strategy}, that is, modulating the frequency of metric collection based on the elapsed runtime of the monitored process. In detail, during the first second, \texttt{denet} samples at the highest frequency (e.g., every 100 ms), ensuring fine-grained resolution during process startup and transient activity spikes. During the next nine seconds, the sampling rate is increased gradually to reach the user-provided maximum interval; this rate is maintained for processes running over 10 s, hence providing full control on the profiling resolution.

This adaptive profiling algorithm enables the characterization of short-lived or dynamic tasks (such as CPU bursts or parallel IO) at high resolution, while also minimizing systems overhead for long running tasks.

\subsection*{Metrics}

The tool collects multiple performance metrics and events:

\begin{enumerate}[itemsep=0pt, topsep=0pt]
    \item CPU usage: Aggregated and per-core, so a 100\% indicates a full single core, and 400\% four full single cores, following top/htop conventions in posix systems.
    \item Memory: Including RSS and VMS separately, hence providing information about peak usage, swapping events, and memory leaks.
    \item Disk reads and writes (IO): Bytes read and written per interval.
    \item Thread counts: Thread counts and child processes spawned from a parent process are tracked and monitored, hence reporting parallelization and forking (e.g., as in frequent alignment tools, such as STAR or BWA). Tracking down the child processes of a parent can be disabled with \texttt{--no-include-children}. 
    \item Exit statuses: Monitored parent process exit code termination, indicating uneventful successes as well as error codes as reported by the process.
    \item Logging: As a summary and metadata, \texttt{denet} reports the full command of the monitored process, the path to its executable, PID, runtime duration, and the profiling strategy (e.g., the \texttt{denet} call, including the adaptive sampling specification, if used.)
\end{enumerate}

\subsection*{eBPF support and off-CPU analysis}

In GNU/Linux systems, \texttt{denet} offers experimental support for extended Berkeley Packet Filter (eBPF), a native Linux kernel technology to run sandboxed programs. eBPF allows safe, low-level event tracing with minimal performance overhead, as it avoids the need for expensive context switches or data transfers between kernel and user space and enables direct instrumentation of kernel functions, system calls, and network events, providing granular visibility into resource utilization \cite{gbadamosi2024ebpf}. 

eBPF effectiveness and low overhead have led to its widespread adoption for performance monitoring in large-scale industrial systems \cite{benson2024netedit}. Crucially for bioinformatics, eBPF is namespace-aware, hence allowing precise and efficient profiling of containerized processes, i.e. running with Docker or apptainer. This enables collecting detailed performance metrics from complex and containerized workflows without altering the application or the host environment.

By using eBPF, \texttt{denet} can quantify off-cpu time, e.g., where the profiled application is spending its time waiting. This provides insights to optimize I/O patterns, fix lock contention, and address other non-computational bottlenecks that would otherwise remain hidden.

\subsection*{Architecture}

\texttt{denet}'s Rust architecture is modular. The Rust library includes: core, for low-level system interaction and sampling reading from /proc on Linux; config, which manages user inputs (e.g., sampling intervals, monitoring and output options); error, to handle exceptions; cpu-sampler, to measure CPU time akin to top and htop; and python, containing the PyO3 bindings that expose the Rust API to python.


\subsection*{Comparison to other tools}

%{\color{red} cite or add \url{https://github.com/WanluLiuLab/labw_proc_profiler} to the table?}

Table~\ref{tab:tool_comparison} describes \texttt{denet}'s capabilities as compared to other profilers and Unix tools.

\begin{table}[ht]
  \centering
  \footnotesize
  \caption{Comparison of process monitoring tools and libraries.}
  \label{tab:tool_comparison}
  \begin{tabularx}{\linewidth}{c c c c c c} %{@{} L L *{5}{C} @{}}
   \toprule
    Tool                    & Output              & Process tree  & API/CLI & Adaptive sampling &  Extensibility     \\
    \midrule
    \texttt{denet}          & Terminal, JSON, CSV & Yes          & Both    & Yes                   & Python, Rust      \\
    \texttt{top/htop}       & Terminal            & Partial      & CLI     & No                    & No                \\
    \texttt{ps}             & Text/CSV            & No           & CLI     & No                    & No                \\
    \texttt{time}           & Text                & No           & CLI     & No                    & No                \\
    \texttt{pidstat}        & Text/CSV            & Partial      & CLI     & No           & No                \\
    \texttt{psutil\cite{rodola2020psutil}/psrecord\cite{psrecord}}& Text/PNG  & Partial      & Both     & No          & Python            \\
%    \texttt{psrecord}       & \textit{todo}       & \textit{todo}& \textit{todo}& \textit{todo} & \textit{todo}     & \textit{todo}     \\
    \bottomrule
  \end{tabularx}
\end{table}


\section*{Usage}

\subsection*{Command-line interface (CLI)}

\texttt{denet}'s CLI is Unix-friendly \cite{raymond1999cathedral} and composable to facilitate inclusion into scripts and workflows (Figure~\ref{fig:cli}).\\

\begin{figure}[H]

\begin{lstlisting}[frame=single,language=bash]
# Real-time monitoring of the process `sleep 5` so profiling results:
#   are reported as (colored) standard output:
denet run sleep 5

# To generate a report in JSON format, including metadata on the first line:
denet --json run sleep 5 > metrics.json

# To modulate the sampling interval (in milliseconds):
denet --interval 500 run sleep 5

# To specify the maximum sampling interval (adaptive sampling mode):
denet --max-interval 2000 run sleep 5

# To monitor an existing running process with PID 1234:
denet attach 1234

# To monitor PID 1234 just for 10 seconds:
denet --duration 10 attach 1234

# To avoid polluting the standard output (quiet mode) 
#   while profiling `python script.py`:
denet --quiet --json --out metrics.jsonl run python script.py

# To disable child process monitoring (only track the parent process):
denet --no-include-children run python multi_process_script.py
\end{lstlisting}

    \caption{Denet's CLI usage examples.}
    \label{fig:cli}
\end{figure}

\subsection*{Application Programming Interface (API)}

\texttt{denet}â€™s fully documented API provides the CLI capabilities using a simple syntax, facilitating metrics postprocessing (e.g., generating aggregated statistics, such as min/max/avg) and import from any python codebase, including Jupyter notebooks. Figure~\ref{fig:api} depicts how to monitor a process and collect the JSON summary using the API.


\begin{figure}[H]
\begin{lstlisting}[frame=single,language=python]
#!/usr/bin/python3
import json
import denet

# Create a monitor for a process
monitor = denet.ProcessMonitor(
    cmd=["python", "-c", "import time; time.sleep(10)"], # command
    base_interval_ms=100,    # Start sampling every 100ms
    max_interval_ms=1000,    # Sample at most every 1000ms
    store_in_memory=True,    # Keep samples in memory
    output_file=None,        # Optional file output
    include_children=True    # Monitor child processes (default True)
)

# Let the monitor run automatically until the process completes.
#   Samples are collected at the specified sampling rate in the background
monitor.run()

# Access all collected samples after process completion
samples = monitor.get_samples()
print(f"Collected {len(samples)} samples")

# Get summary statistics
summary_json = monitor.get_summary()
\end{lstlisting}

\caption{Denet's API usage example. \label{fig:api}}
\end{figure}



%\subsection{Using denet to profile bwa-mem alignment performance}

%{\color{red} do some bwa-mem here}


\section*{Conclusion}

\texttt{denet} is a lightweight and customizable process monitoring tool purposefully built for the needs of modern bioinformatics workflows and benchmarks. As compared to other tools, Denet provides adaptive sampling, recursive process tree monitoring, and eBPF support.  Its dual interface, including a CLI for interactive usage or POSIX workflows, and a Python API for flexible programming, provides extra flexibility. \texttt{denet} is free software.

In terms of limitations, \texttt{denet} is built with Linux in mind, even if macOS might be supported via host APIs; and does not profile GPU usage.

\section*{Competing interests}

The authors declare no competing interests.

\section*{Funding}

This project received no specific funding. IM acknowledges the University of Zurich GRC Career Grant 2025\_Q1\_CG\_001.

\section*{Acknowledgements}

We thank Mark D. Robinson for constructive feedback.

\section*{Authors' contributions}

BC and IM conceived the project. BC coded the tool. IM drafted the first version of the manuscript.

\bibliographystyle{unsrt}
\bibliography{refs}

\clearpage

%\beginsupplement
%\section{Supplementary material}  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\subsection{Supplementary figures}  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\end{document}